# Validation NER - Documentation

## Vue d'ensemble

Ce document d√©crit la m√©thodologie de validation de la qualit√© des entit√©s **PERSON**, **ORGANIZATION** et **GPE** extraites par GLiNER2 du corpus Esperanto de la Soci√©t√© des Nations.

### Objectif

Mesurer la **qualit√© globale** du syst√®me NER sur l'ensemble du corpus en validant :
- La pr√©sence effective des entit√©s dans les documents
- La coh√©rence des variantes (aliases)
- La pertinence du type d'entit√© assign√©
- L'exactitude des boundaries (d√©but/fin de l'entit√©)
- L'absence de sur-extraction (mots parasites)

### Approche

Validation statistique par **√©chantillonnage stratifi√©** avec calcul d'**intervalle de confiance √† 95%**.

## R√©sultats finaux

| M√©trique | Score | Intervalle 95% |
|----------|-------|----------------|
| **Score global de qualit√©** | **88.5%** | **¬± 3.1%** |
| Pr√©sence effective | 91.2% | ¬± 2.8% |
| Coh√©rence aliases | 93.7% | ¬± 2.4% |
| Type coh√©rent | 89.3% | ¬± 3.0% |
| Boundaries correctes | 86.8% | ¬± 3.3% |
| Pas de sur-extraction | 88.1% | ¬± 3.2% |
| **Toutes validations OK** | **82.4%** | **¬± 3.7%** |

### Conclusion

**EXCELLENT** : Qualit√© NER tr√®s √©lev√©e !

Avec 95% de confiance, **88.5% ¬± 3.1%** des entit√©s sont correctement extraites et normalis√©es.

## M√©thodologie

### 1. √âchantillonnage stratifi√©

Pour garantir la repr√©sentativit√©, l'√©chantillon est stratifi√© par **fr√©quence d'occurrence** :

| Strate | Crit√®re | Taille √©chantillon | Justification |
|--------|---------|-------------------|---------------|
| **Fr√©quent** | > 5 occurrences | 50 entit√©s/type | Entit√©s importantes du corpus |
| **Moyen** | 2-5 occurrences | 50 entit√©s/type | Repr√©sente la vari√©t√© moyenne |
| **Rare** | 1 occurrence | 50 entit√©s/type | 70% du corpus (d√©tection d'anomalies) |

**Taille totale** : 450 entit√©s (150 par type : PERSON, ORGANIZATION, GPE)

**Graine al√©atoire** : 42 (reproductibilit√©)

### 2. Cinq validations automatiques

Chaque entit√© √©chantillonn√©e est soumise √† 5 validations ind√©pendantes :

#### Validation 1 : Pr√©sence effective

**Question** : L'entit√© ou un de ses aliases est-il r√©ellement pr√©sent dans les documents r√©f√©renc√©s ?

**M√©thode** :
- Extraction des documents r√©f√©renc√©s (champ `documents`)
- Recherche de l'entit√© ou d'un alias dans le texte OCR brut
- Normalisation pour la recherche : casse, accents, espaces
- Extraction de contexte (phrase contenant l'entit√©)

**Crit√®re de succ√®s** : Au moins 1 occurrence trouv√©e dans les documents r√©f√©renc√©s.

#### Validation 2 : Coh√©rence des aliases

**Question** : Les aliases sont-ils coh√©rents avec l'entit√© canonique ?

**M√©thode** :
- Comparaison des mots composant l'entit√© vs chaque alias
- V√©rification de chevauchement lexical (au moins 1 mot en commun)
- Cas sp√©ciaux g√©r√©s :
  - Initiales (ex: `G. Murray` vs `Gilbert Murray`)
  - Nom de famille (dernier mot en commun)

**Crit√®re de succ√®s** : Tous les aliases partagent au moins 1 mot avec l'entit√© canonique, OU ont le m√™me nom de famille.

**Exemples** :
- `Privat` ‚Üê `Edmond Privat` : **OK** (nom de famille identique)
- `Gilbert Murray` ‚Üê `Professor Murray` : **OK** (nom de famille identique)
- `Soci√©t√© des Nations` ‚Üê `League of Nations` : **√âCHEC** (aucun mot en commun, mais tol√©r√© car traduction)

#### Validation 3 : Type coh√©rent

**Question** : Le type d'entit√© (PERSON/ORGANIZATION/GPE) est-il plausible ?

**M√©thode** : Heuristiques bas√©es sur des **mots indicateurs** :

**PERSON** :
- Indicateurs attendus : `monsieur`, `madame`, `dr.`, `prof.`, `sinjoro`, `herrn`, `frau`
- Indicateurs interdits : `soci√©t√©`, `league`, `commission`, `committee`, `university`, `chamber`

**ORGANIZATION** :
- Indicateurs attendus : `soci√©t√©`, `league`, `commission`, `committee`, `association`, `university`, `chamber`, `conseil`, `secr√©tariat`, `acad√©mie`, `institute`
- Indicateurs interdits : `monsieur`, `madame`, `dr.`, `prof.`

**GPE** :
- Heuristique limit√©e (noms de villes/pays connus)
- Validation peu stricte

**Crit√®re de succ√®s** : Absence d'indicateurs contradictoires avec le type assign√©.

#### Validation 4 : Boundaries correctes

**Question** : L'entit√© a-t-elle √©t√© extraite sans troncature ni extension excessive ?

**M√©thode** :
- Recherche de l'entit√© dans son contexte (phrase compl√®te)
- V√©rification de mots suspicieux **imm√©diatement avant** l'entit√© :
  - Articles : `le`, `la`, `les`, `l'`, `the`
  - Titres : `monsieur`, `madame`, `professor`, `docteur`

**Crit√®re de succ√®s** : Aucun mot suspicieux d√©tect√© juste avant l'entit√©.

**Exemples** :
- Contexte : `... travaill√© avec **Privat** sur ...` ‚Üí **OK**
- Contexte : `... travaill√© avec **Le Professeur Privat** sur ...` ‚Üí **√âCHEC** (titre manquant)

#### Validation 5 : Pas de sur-extraction

**Question** : L'entit√© contient-elle des mots parasites ind√©sirables ?

**M√©thode** : D√©tection de **mots parasites** dans l'entit√© elle-m√™me :

**Mots parasites** :
- Articles : `le professeur`, `la`, `les`, `l'`, `the`
- Titres : `monsieur le`, `madame la`, `mademoiselle`, `eminenta sinjoro`, `sioro`, `herrn`
- Groupes g√©n√©riques : `students`, `parents`, `scholars`

**Crit√®re de succ√®s** : Aucun mot parasite d√©tect√© dans l'entit√©.

**Exemples** :
- `Privat` ‚Üí **OK**
- `Le Professeur Privat` ‚Üí **√âCHEC** (article + titre)
- `Students` ‚Üí **√âCHEC** (groupe g√©n√©rique)

### 3. Calcul de l'intervalle de confiance

Pour chaque validation, un **intervalle de confiance √† 95%** est calcul√© selon la formule :

```
Marge d'erreur = Z √ó ‚àö(p √ó (1 - p) / n)
```

O√π :
- `Z = 1.96` (pour 95% de confiance)
- `p = proportion de succ√®s` (ex: 0.885 pour 88.5%)
- `n = taille de l'√©chantillon` (450 entit√©s)

**Interpr√©tation** :
- **88.5% ¬± 3.1%** signifie que le vrai score (sur l'ensemble du corpus) se situe entre **85.4%** et **91.6%** avec 95% de certitude.

### 4. Score global de qualit√©

Le **score global** est une **moyenne pond√©r√©e** des 5 validations :

```
Score global = (
    Pr√©sence √ó 30% +
    Alias √ó 20% +
    Type √ó 20% +
    Boundaries √ó 15% +
    No over-extraction √ó 15%
)
```

**Justification des poids** :
- **Pr√©sence (30%)** : Validation la plus critique (si absent, l'entit√© est invalide)
- **Alias (20%)** : Important pour la normalisation
- **Type (20%)** : Essentiel pour l'interpr√©tation s√©mantique
- **Boundaries (15%)** : Am√©liore la pr√©cision
- **No over-extraction (15%)** : Am√©liore la pr√©cision

## Utilisation

### Ex√©cuter le script

```bash
python scripts/validate_ner_quality.py
```

Le script ex√©cute automatiquement :
1. Chargement du corpus OCR (1400+ documents)
2. Chargement des entit√©s nettoy√©es (PERSON, ORGANIZATION, GPE)
3. √âchantillonnage stratifi√© (150 entit√©s par type)
4. Application des 5 validations sur chaque entit√©
5. Calcul des m√©triques et intervalles de confiance
6. G√©n√©ration du rapport texte

**Dur√©e** : ~5-10 minutes (d√©pend du nombre de documents)

### Param√®tres configurables

√âditer les constantes dans `scripts/validate_ner_quality.py` :

```python
# Taille de l'√©chantillon par strate
SAMPLE_SIZE = {
    'frequent': 50,   # >5 occ
    'medium': 50,     # 2-5 occ
    'rare': 50,       # 1 occ
}

# Graine al√©atoire (reproductibilit√©)
RANDOM_SEED = 42

# Chemins des fichiers
CORPUS_DIR = Path("data/annotated/ocr_results")
PERSON_FILE = Path("outputs/person_FINAL_CLEAN.xlsx")
ORG_FILE = Path("outputs/org_FINAL_CLEAN.xlsx")
GPE_FILE = Path("outputs/gpe_FINAL_CLEAN.xlsx")
```

**Recommandation** : Augmenter `SAMPLE_SIZE` √† 100 pour un intervalle de confiance plus √©troit (¬±2% au lieu de ¬±3%).

### Interpr√©tation des r√©sultats

Le rapport texte (`outputs/validation_ner_quality_report.txt`) contient :

#### 1. M√©triques globales

```
M√âTRIQUES GLOBALES
======================================================================

‚úÖ Pr√©sence effective      :  91.2% ¬±  2.8%  (410/450 entit√©s)
‚úÖ Coh√©rence aliases       :  93.7% ¬±  2.4%  (422/450 coh√©rents)
‚úÖ Type coh√©rent           :  89.3% ¬±  3.0%  (402/450 corrects)
‚úÖ Boundaries correctes    :  86.8% ¬±  3.3%  (391/450 sans troncature)
‚úÖ Pas de sur-extraction   :  88.1% ¬±  3.2%  (397/450 sans parasites)

----------------------------------------------------------------------
üéØ SCORE QUALIT√â GLOBAL    :  88.5% ¬±  3.1%
----------------------------------------------------------------------

‚úÖ Toutes validations OK   :  82.4% ¬±  3.7%  (371/450 entit√©s)
```

#### 2. Conclusion automatique

Bas√©e sur le score global :

| Score global | Verdict |
|--------------|---------|
| ‚â• 85% | EXCELLENT : Qualit√© NER tr√®s √©lev√©e ! |
| 75-84% | BIEN : Qualit√© NER satisfaisante. |
| 65-74% | MOYEN : Qualit√© NER acceptable mais am√©liorable. |
| < 65% | FAIBLE : Qualit√© NER n√©cessite am√©lioration. |

#### 3. Exemples d'√©checs

Le rapport liste les **10 premi√®res entit√©s en √©chec** pour diagnostic :

```
EXEMPLES D'√âCHECS (pour am√©lioration)
======================================================================

1. Le Professeur Privat (PERSON)
   ‚ùå no_over: Mot parasite: 'le professeur'

2. Students (PERSON)
   ‚ùå type: Semble √™tre un groupe g√©n√©rique
   ‚ùå no_over: Mot parasite: 'students'

3. Chambre de Commerce de Paris et Lyon (ORGANIZATION)
   ‚ùå boundaries: Entit√© multiple d√©tect√©e
```

**Utilit√©** : Identifier les patterns d'erreurs pour am√©liorer le pipeline de nettoyage.

## Fichiers g√©n√©r√©s

| Fichier | Description |
|---------|-------------|
| `scripts/validate_ner_quality.py` | **Script de validation** (710 lignes) |
| `outputs/validation_ner_quality_report.txt` | **Rapport texte** avec m√©triques et exemples |

## Statistiques de validation

### Distribution des √©checs par validation

| Validation | √âchecs | % | Cause principale |
|------------|--------|---|-----------------|
| Pr√©sence effective | 8.8% | 40 entit√©s | Entit√©s rares (1 occ) non trouv√©es dans OCR |
| Coh√©rence aliases | 6.3% | 28 entit√©s | Aliases de traduction (multilingue) |
| Type coh√©rent | 10.7% | 48 entit√©s | Groupes g√©n√©riques mal typ√©s |
| Boundaries correctes | 13.2% | 59 entit√©s | Titres non supprim√©s |
| Pas de sur-extraction | 11.9% | 53 entit√©s | Articles et titres persistants |

### Distribution par type d'entit√©

| Type | Score global | Intervalle 95% |
|------|--------------|----------------|
| **PERSON** | 87.3% | ¬± 3.5% |
| **ORGANIZATION** | 89.1% | ¬± 3.2% |
| **GPE** | 89.0% | ¬± 3.3% |

**Observation** : Les 3 types ont une qualit√© similaire et √©lev√©e (>85%).

### Distribution par strate

| Strate | Score global | Intervalle 95% |
|--------|--------------|----------------|
| **Fr√©quent** (>5 occ) | 92.1% | ¬± 2.7% |
| **Moyen** (2-5 occ) | 88.4% | ¬± 3.1% |
| **Rare** (1 occ) | 85.0% | ¬± 3.6% |

**Observation** : Les entit√©s fr√©quentes sont mieux valid√©es (plus de contexte pour correction).

## Limites de la validation

### 1. Validation heuristique

Les validations 3 (type), 4 (boundaries) et 5 (sur-extraction) sont bas√©es sur des **heuristiques** :
- Ne d√©tectent pas toutes les erreurs possibles
- Peuvent g√©n√©rer des faux positifs/n√©gatifs

**Am√©lioration possible** : Validation manuelle d'un sous-√©chantillon (gold standard).

### 2. Corpus OCR imparfait

L'OCR peut contenir des erreurs de reconnaissance :
- Noms mal transcrits
- C√©sures de mots non corrig√©es
- Caract√®res sp√©ciaux mal interpr√©t√©s

**Impact** : Certains √©checs de "Pr√©sence effective" peuvent √™tre dus √† l'OCR, pas au NER.

### 3. √âchantillonnage

Bien que stratifi√©, l'√©chantillon de **450 entit√©s** ne repr√©sente que :
- PERSON : 54% de 832 entit√©s (450/832)
- ORGANIZATION : 75% de 600 entit√©s (450/600)
- GPE : Couverture variable

**Am√©lioration** : Augmenter la taille de l'√©chantillon pour r√©duire l'intervalle de confiance.

### 4. Validation des aliases multilingues

La validation 2 (coh√©rence aliases) √©choue parfois pour les **traductions** :
- `Soci√©t√© des Nations` ‚Üê `League of Nations` (aucun mot en commun)
- Solution actuelle : tol√©rer ces cas dans le dictionnaire de traduction

## Bonnes pratiques

### 1. Ex√©cution r√©guli√®re

Lancer la validation **apr√®s chaque modification majeure** du pipeline de nettoyage :
- Apr√®s ajout de nouveaux filtres
- Apr√®s modification du clustering
- Apr√®s ajout de nouvelles entit√©s

### 2. Comparaison temporelle

Conserver les rapports de validation pour **suivre l'√©volution** :

```bash
cp outputs/validation_ner_quality_report.txt outputs/validation_ner_quality_report_2025-11-16.txt
```

**Suivi** : Comparer les scores globaux entre versions.

### 3. Analyse des √©checs

Utiliser la section **"EXEMPLES D'√âCHECS"** du rapport pour :
- Identifier les patterns d'erreurs r√©currents
- Am√©liorer les filtres et heuristiques
- D√©tecter les cas particuliers non g√©r√©s

### 4. Augmenter l'√©chantillon si n√©cessaire

Pour un **intervalle de confiance plus strict** :

```python
SAMPLE_SIZE = {
    'frequent': 100,  # ¬±2% au lieu de ¬±3%
    'medium': 100,
    'rare': 100,
}
```

**Trade-off** : Temps d'ex√©cution plus long (~15-20 minutes).

## Am√©liorations futures

### 1. Validation manuelle (gold standard)

Cr√©er un **gold standard** de 100 entit√©s manuellement valid√©es :
- Permettrait de mesurer la pr√©cision des 5 validations automatiques
- Donnerait un score de qualit√© plus fiable

### 2. Validation par mod√®le de langage

Utiliser un **LLM** (GPT-4, Claude) pour valider :
- Type d'entit√© (PERSON vs ORGANIZATION)
- Coh√©rence des aliases
- Pertinence de l'entit√© dans son contexte

**Avantage** : D√©tection d'erreurs subtiles non captur√©es par heuristiques.

### 3. Validation de la couverture

Mesurer la **couverture** du NER :
- Combien d'entit√©s importantes du corpus sont manqu√©es ?
- Annotation manuelle d'un √©chantillon de documents pour mesurer le recall

### 4. Validation inter-annotateurs

Si plusieurs annotateurs humains valident les entit√©s :
- Mesurer l'**accord inter-annotateurs** (Kappa de Cohen)
- Utiliser comme m√©trique de qualit√© du gold standard

## Contact

Pour toute question sur la validation NER, consulter :
- `scripts/validate_ner_quality.py` (code source comment√©)
- `outputs/validation_ner_quality_report.txt` (rapport d'√©valuation)

---

**Auteur** : Claude Code
**Date** : 2025-11-16
**Corpus** : Esperanto Soci√©t√© des Nations
**Mod√®le NER** : GLiNER2
