# ü§ñ models/

**Mod√®les et configurations pour NER**

Ce dossier contient les configurations GLiNER2 et les mod√®les t√©l√©charg√©s.

---

## Structure

```
models/
‚îú‚îÄ‚îÄ configs/         # Configurations NER (labels, param√®tres)
‚îî‚îÄ‚îÄ checkpoints/     # Mod√®les t√©l√©charg√©s (git-ignored)
```

---

## üìÅ Sous-dossiers

### `configs/`
**Contenu** : Fichiers de configuration pour GLiNER2

**Fichiers principaux** :
- `labels.yaml` - D√©finition des labels d'entit√©s NER
- `extraction_params.yaml` - Param√®tres d'extraction (threshold, batch size, etc.)

**Exemple `labels.yaml`** :
```yaml
# Labels pour extraction NER zeroshot avec GLiNER2
# Adapt√© au corpus SDN-Esperanto

labels:
  - PERSON          # Noms de personnes
  - ORGANIZATION    # Organisations, comit√©s, institutions
  - LOCATION        # Lieux, pays, villes
  - EVENT           # √âv√©nements historiques, conf√©rences
  - DATE            # Dates et p√©riodes temporelles
```

**Exemple `extraction_params.yaml`** :
```yaml
# Param√®tres GLiNER2
model_name: "urchade/gliner_multi-v2.1"
threshold: 0.5          # Seuil de confiance minimum
batch_size: 8           # Taille de batch pour traitement
max_length: 384         # Longueur max en tokens
device: "cuda"          # "cuda" ou "cpu"
```

### `checkpoints/`
**Contenu** : Mod√®les GLiNER2 t√©l√©charg√©s depuis Hugging Face

**Git-ignored** : OUI (trop volumineux, ~500MB)

**T√©l√©chargement** :
```bash
./scripts/download_models.sh
```

**Structure attendue** :
```
checkpoints/
‚îî‚îÄ‚îÄ gliner_multi-v2.1/
    ‚îú‚îÄ‚îÄ config.json
    ‚îú‚îÄ‚îÄ pytorch_model.bin
    ‚îú‚îÄ‚îÄ tokenizer_config.json
    ‚îî‚îÄ‚îÄ vocab.txt
```

---

## üöÄ Utilisation

### D√©finir les Labels NER

Cr√©ez `configs/labels.yaml` avec les types d'entit√©s pertinents pour votre corpus :

```yaml
labels:
  - PERSON
  - ORGANIZATION
  - LOCATION
  # Ajoutez d'autres labels selon vos besoins
```

### T√©l√©charger le Mod√®le

```bash
./scripts/download_models.sh
```

### Utiliser le Mod√®le

```python
from transformers import AutoTokenizer, AutoModelForTokenClassification

model_path = "models/checkpoints/gliner_multi-v2.1"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForTokenClassification.from_pretrained(model_path)
```

Ou via GLiNER (recommand√©) :
```python
from gliner import GLiNER

model = GLiNER.from_pretrained("models/checkpoints/gliner_multi-v2.1")
entities = model.predict_entities(text, labels=["PERSON", "LOCATION"])
```

---

## üìù TODO

- [ ] Cr√©er `configs/labels.yaml` avec labels adapt√©s au corpus SDN
- [ ] T√©l√©charger mod√®le GLiNER2 (`./scripts/download_models.sh`)
- [ ] Tester extraction sur exemples (`notebooks/02_ner/gliner_testing.ipynb`)
- [ ] Ajuster threshold selon F1-score obtenu

---

**Voir aussi** : `docs/METHODOLOGY.md` (section "Extraction NER")
